{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 4, Sprint 1, Module 3*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification (Assignment)\n",
    "\n",
    "This notebook is for you to practice skills during lecture.\n",
    "\n",
    "Today's guided module project and assignment will be different. You already know how to do classification. You ready know how to extract features from documents. So? That means you're ready to combine and practice those skills in a kaggle competition. We we will open with a five minute sprint explaining the competition, and then give you 25 minutes to work. After those twenty five minutes are up, I will give a 5-minute demo an NLP technique that will help you with document classification (*and **maybe** the competition*).\n",
    "\n",
    "Today's all about having fun and practicing your skills.\n",
    "\n",
    "## Sections\n",
    "* <a href=\"#p1\">Part 1</a>: Text Feature Extraction & Classification Pipelines\n",
    "* <a href=\"#p2\">Part 2</a>: Latent Semantic Indexing\n",
    "* <a href=\"#p3\">Part 3</a>: Word Embeddings with Spacy\n",
    "* <a href=\"#p4\">Part 4</a>: Post Lecture Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Feature Extraction & Classification Pipelines (Learn)\n",
    "<a id=\"p1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along \n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model (try using the pipe method I just demoed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Competition Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# You may need to change the path\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1321</td>\n",
       "      <td>\\nSometimes, when whisky is batched, a few lef...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3861</td>\n",
       "      <td>\\nAn uncommon exclusive bottling of a 6 year o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>655</td>\n",
       "      <td>\\nThis release is a port version of Amrut’s In...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>555</td>\n",
       "      <td>\\nThis 41 year old single cask was aged in a s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1965</td>\n",
       "      <td>\\nQuite herbal on the nose, with aromas of dri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                        description  ratingCategory\n",
       "0  1321  \\nSometimes, when whisky is batched, a few lef...               1\n",
       "1  3861  \\nAn uncommon exclusive bottling of a 6 year o...               0\n",
       "2   655  \\nThis release is a port version of Amrut’s In...               1\n",
       "3   555  \\nThis 41 year old single cask was aged in a s...               1\n",
       "4  1965  \\nQuite herbal on the nose, with aromas of dri...               1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2), min_df=.03)\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "pipe = Pipeline([('vect', vect), ('clf', clf)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Your Search Space\n",
    "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   24.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=4)]: Done 1440 out of 1440 | elapsed: 12.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=0.03,\n",
       "                                                        ngram_range=(1, 2),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words='english',\n",
       "                                                        st...\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=None,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=4,\n",
       "             param_grid={'clf__max_depth': (5, 10, 15, 20),\n",
       "                         'clf__n_estimators': (5, 10),\n",
       "                         'vect__max_df': (0.75, 0.9, 1.0),\n",
       "                         'vect__max_features': (500, 750, 1000),\n",
       "                         'vect__min_df': (0.02, 0.03, 0.04, 0.05)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'vect__min_df': (.02, .03, .04, .05),\n",
    "    'vect__max_df': (0.75, 0.90, 1.0),\n",
    "    'vect__max_features': (500, 750, 1000),\n",
    "    'clf__max_depth':(5,10,15,20),\n",
    "    'clf__n_estimators': (5, 10)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe,parameters, cv=5, n_jobs=4, verbose=1)\n",
    "grid_search.fit(train['description'], train['ratingCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7198433053122372"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__max_depth': 15,\n",
       " 'clf__n_estimators': 10,\n",
       " 'vect__max_df': 1.0,\n",
       " 'vect__max_features': 500,\n",
       " 'vect__min_df': 0.02}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File\n",
    "*Note:* In a typical Kaggle competition, you are only allowed two submissions a day, so you only submit if you feel you cannot achieve higher test accuracy. For this competition the max daily submissions are capped at **20**. Submit for each demo and for your assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = grid_search.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461               1\n",
       "1  2604               1\n",
       "2  3341               1\n",
       "3  3764               1\n",
       "4  2306               1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "subNumber = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'./data/submission1.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "You're trying to achieve a minimum of 70% Accuracy on your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Indexing (Learn)\n",
    "<a id=\"p2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "4. Make a submission to Kaggle \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "         steps=[('lsi',\n",
      "                 Pipeline(memory=None,\n",
      "                          steps=[('vect',\n",
      "                                  TfidfVectorizer(analyzer='word', binary=False,\n",
      "                                                  decode_error='strict',\n",
      "                                                  dtype=<class 'numpy.float64'>,\n",
      "                                                  encoding='utf-8',\n",
      "                                                  input='content',\n",
      "                                                  lowercase=True, max_df=1.0,\n",
      "                                                  max_features=None,\n",
      "                                                  min_df=0.03,\n",
      "                                                  ngram_range=(1, 2), norm='l2',\n",
      "                                                  preprocessor=None,\n",
      "                                                  smooth_idf=True,\n",
      "                                                  stop_words='english',\n",
      "                                                  strip_accen...\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=15, max_features='auto',\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=1, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=10, n_jobs=-1,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2), min_df=.03)\n",
    "svd = TruncatedSVD(n_components=100, \n",
    "                   algorithm='randomized',\n",
    "                   n_iter=10)\n",
    "\n",
    "lsi = Pipeline([('vect', vect), ('svd', svd)])\n",
    "clf = RandomForestClassifier(max_depth=15, n_estimators=10, n_jobs=-1)\n",
    "\n",
    "pipe = Pipeline([('lsi', lsi), ('clf', clf)])\n",
    "\n",
    "print(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Your Search Space\n",
    "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   28.7s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=4)]: Done 1620 out of 1620 | elapsed: 14.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('lsi',\n",
       "                                        Pipeline(memory=None,\n",
       "                                                 steps=[('vect',\n",
       "                                                         TfidfVectorizer(analyzer='word',\n",
       "                                                                         binary=False,\n",
       "                                                                         decode_error='strict',\n",
       "                                                                         dtype=<class 'numpy.float64'>,\n",
       "                                                                         encoding='utf-8',\n",
       "                                                                         input='content',\n",
       "                                                                         lowercase=True,\n",
       "                                                                         max_df=1.0,\n",
       "                                                                         max_features=None,\n",
       "                                                                         min_df=0.03,\n",
       "                                                                         ngram_range=(1,\n",
       "                                                                                      2),\n",
       "                                                                         norm='l2',\n",
       "                                                                         preprocessor=None,\n",
       "                                                                         smoo...\n",
       "                                                               random_state=None,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=4,\n",
       "             param_grid={'clf__max_depth': (5, 10, 15, 20),\n",
       "                         'clf__n_estimators': (5, 10, 15),\n",
       "                         'lsi__svd__n_components': [10, 100, 250],\n",
       "                         'lsi__vect__max_df': (0.75, 0.9, 1.0),\n",
       "                         'lsi__vect__min_df': (0.03, 0.05, 0.07)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "parameters = {\n",
    "    'lsi__svd__n_components': [10,100,250],\n",
    "    'lsi__vect__max_df': (0.75, .9, 1.0),\n",
    "    'lsi__vect__min_df': (.03, .05, .07),\n",
    "    'clf__max_depth':(5,10,15,20),\n",
    "    'clf__n_estimators': (5, 10, 15)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe,parameters, cv=5, n_jobs=4, verbose=1)\n",
    "grid_search.fit(train['description'], train['ratingCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7203364925647833"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__max_depth': 5,\n",
       " 'clf__n_estimators': 10,\n",
       " 'lsi__svd__n_components': 10,\n",
       " 'lsi__vect__max_df': 0.9,\n",
       " 'lsi__vect__min_df': 0.03}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = grid_search.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461               1\n",
       "1  2604               1\n",
       "2  3341               1\n",
       "3  3764               1\n",
       "4  2306               1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Continue to apply Latent Semantic Indexing (LSI) to various datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings with Spacy (Learn)\n",
    "<a id=\"p3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to your Dataset\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_dist = {\n",
    "    \n",
    "    'max_depth' : randint(3,10),\n",
    "    'min_samples_leaf': randint(2,15)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue Word Embedding Work Here\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['description'] = train['description'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_word_vectors(docs):\n",
    "    return [nlp(doc).vector for doc in docs]\n",
    "\n",
    "X_train = get_word_vectors(train['description'])\n",
    "\n",
    "len(X_train) == len(train['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    \n",
    "    'max_depth' : randint(3,10),\n",
    "    'min_samples_leaf': randint(2,15),\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "rfc = RandomForestClassifier(**param_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'float' and 'rv_frozen'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-9deadb1f65c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrfc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ratingCategory'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\U4-S1-NLP\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    381\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[1;32m--> 383\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\U4-S1-NLP\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1043\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\U4-S1-NLP\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\U4-S1-NLP\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    655\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 657\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    659\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\U4-S1-NLP\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mworker\u001b[1;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[0mjob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\U4-S1-NLP\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    591\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m             \u001b[1;31m# We capture the KeyboardInterrupt and reraise it as\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\U4-S1-NLP\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 253\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\U4-S1-NLP\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 253\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\U4-S1-NLP\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    163\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\U4-S1-NLP\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    875\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 877\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    878\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\U4-S1-NLP\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mmin_samples_leaf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# float\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m0.\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_samples_leaf\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m                 raise ValueError(\"min_samples_leaf must be at least 1 \"\n\u001b[0;32m    214\u001b[0m                                  \u001b[1;34m\"or in (0, 0.5], got %s\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'float' and 'rv_frozen'"
     ]
    }
   ],
   "source": [
    "rfc.fit(X_train, train['ratingCategory'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = ...predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "    - Try to extract word embeddings with Spacy and use those embeddings as your features for a classification model.\n",
    "4. Make a submission to Kaggle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Lecture Assignment\n",
    "<a id=\"p4\"></a>\n",
    "\n",
    "Your primary assignment this afternoon is to achieve a minimum of 70% accuracy on the Kaggle competition. Once you have achieved 70% accuracy, please work on the following: \n",
    "\n",
    "1. Research \"Sentiment Analysis\". Provide answers in markdown to the following questions: \n",
    "    - What is \"Sentiment Analysis\"? \n",
    "    - Is Document Classification different than \"Sentiment Analysis\"? Provide evidence for your response\n",
    "    - How do create labeled sentiment data? Are those labels really sentiment?\n",
    "    - What are common applications of sentiment analysis?\n",
    "2. Research our why word embeddings worked better for the lecture notebook than on the whiskey competition.\n",
    "    - This [text classification documentation](https://developers.google.com/machine-learning/guides/text-classification/step-2-5) from Google might be of interest\n",
    "    - Neural Networks are becoming more popular for document classification. Why is that the case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# path to read data\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "minority = train[train['ratingCategory'] == 0]\n",
    "majority = train[train['ratingCategory'] == 1]\n",
    "\n",
    "df_minority_upsampled = resample(minority,\n",
    "                                 replace=True,\n",
    "                                 n_samples=majority.shape[0]\n",
    "                                )\n",
    "\n",
    "df_upsampled = pd.concat([majority, df_minority_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1321</td>\n",
       "      <td>\\nSometimes, when whisky is batched, a few lef...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3861</td>\n",
       "      <td>\\nAn uncommon exclusive bottling of a 6 year o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>655</td>\n",
       "      <td>\\nThis release is a port version of Amrut’s In...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>555</td>\n",
       "      <td>\\nThis 41 year old single cask was aged in a s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1965</td>\n",
       "      <td>\\nQuite herbal on the nose, with aromas of dri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                        description  ratingCategory\n",
       "0  1321  \\nSometimes, when whisky is batched, a few lef...               1\n",
       "1  3861  \\nAn uncommon exclusive bottling of a 6 year o...               0\n",
       "2   655  \\nThis release is a port version of Amrut’s In...               1\n",
       "3   555  \\nThis 41 year old single cask was aged in a s...               1\n",
       "4  1965  \\nQuite herbal on the nose, with aromas of dri...               1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(x='ratingCategory', data=df_upsampled);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2881\n",
       "0    1141\n",
       "2      65\n",
       "Name: ratingCategory, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['ratingCategory'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2881\n",
       "0    2881\n",
       "Name: ratingCategory, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_upsampled['ratingCategory'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "pipe = Pipeline([('vect', vect), ('clf', clf)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   44.3s\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 2),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words='english',\n",
       "                                                        strip...\n",
       "                                                               min_samples_split=2,\n",
       "                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                               n_estimators=100,\n",
       "                                                               n_jobs=-1,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=None,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'clf__max_depth': (5, 10, 15, 20),\n",
       "                         'vect__max_df': (0.75, 0.9, 1),\n",
       "                         'vect__min_df': (0.03, 0.05, 0.1)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'vect__max_df': (.75, .9, 1),\n",
    "    'vect__min_df': (.03, .05, .1),\n",
    "    'clf__max_depth': (5, 10, 15, 20)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe, params, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(df_upsampled['description'], df_upsampled['ratingCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87556615592175"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 95.20430633716663%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = grid_search.predict(train['description'])\n",
    "\n",
    "acc_score = accuracy_score(train['ratingCategory'], y_pred)\n",
    "\n",
    "print(f'Accuracy Score: {(acc_score)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = grid_search.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory': pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461               1\n",
       "1  2604               1\n",
       "2  3341               0\n",
       "3  3764               1\n",
       "4  2306               1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to improve the model by using upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "         steps=[('lsi',\n",
      "                 Pipeline(memory=None,\n",
      "                          steps=[('vect',\n",
      "                                  TfidfVectorizer(analyzer='word', binary=False,\n",
      "                                                  decode_error='strict',\n",
      "                                                  dtype=<class 'numpy.float64'>,\n",
      "                                                  encoding='utf-8',\n",
      "                                                  input='content',\n",
      "                                                  lowercase=True, max_df=1.0,\n",
      "                                                  max_features=None,\n",
      "                                                  min_df=0.03,\n",
      "                                                  ngram_range=(1, 2), norm='l2',\n",
      "                                                  preprocessor=None,\n",
      "                                                  smooth_idf=True,\n",
      "                                                  stop_words='english',\n",
      "                                                  strip_accen...\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=15, max_features='auto',\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=1, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=10, n_jobs=-1,\n",
      "                                        oob_score=False, random_state=3,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n"
     ]
    }
   ],
   "source": [
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2), min_df=.03)\n",
    "svd = TruncatedSVD(n_components=100, \n",
    "                   algorithm='randomized',\n",
    "                   n_iter=10,\n",
    "                   random_state=3\n",
    "                  )\n",
    "\n",
    "lsi = Pipeline([('vect', vect), ('svd', svd)])\n",
    "clf = RandomForestClassifier(max_depth=15, n_estimators=10, n_jobs=-1, random_state=3)\n",
    "\n",
    "pipe = Pipeline([('lsi', lsi), ('clf', clf)])\n",
    "\n",
    "print(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1944 candidates, totalling 9720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   34.8s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed: 15.1min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed: 21.1min\n",
      "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed: 28.3min\n",
      "[Parallel(n_jobs=4)]: Done 3192 tasks      | elapsed: 36.9min\n",
      "[Parallel(n_jobs=4)]: Done 4042 tasks      | elapsed: 46.4min\n",
      "[Parallel(n_jobs=4)]: Done 4992 tasks      | elapsed: 57.1min\n",
      "[Parallel(n_jobs=4)]: Done 6042 tasks      | elapsed: 69.5min\n",
      "[Parallel(n_jobs=4)]: Done 7192 tasks      | elapsed: 82.3min\n",
      "[Parallel(n_jobs=4)]: Done 8442 tasks      | elapsed: 94.8min\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'lsi__svd__n_components': [10,100,250],\n",
    "    'lsi__svd__n_iter': (5, 10),\n",
    "    'lsi__vect__max_df': (0.75, 0.85, 0.95),\n",
    "    'lsi__vect__min_df': (.03, .05, .07),\n",
    "    'clf__max_depth':(5,10,15,20),\n",
    "    'clf__n_estimators': (10, 15, 25),\n",
    "    'clf__min_samples_leaf': (2, 3, 4)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe,parameters, cv=5, n_jobs=4, verbose=1)\n",
    "grid_search.fit(df_upsampled['description'], df_upsampled['ratingCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7257184583110131"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__max_depth': 25,\n",
       " 'clf__n_estimators': 30,\n",
       " 'lsi__svd__n_components': 100,\n",
       " 'lsi__vect__max_df': 0.75,\n",
       " 'lsi__vect__min_df': 0.02,\n",
       " 'lsi__vect__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 98.16491313922192%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = grid_search.predict(train['description'])\n",
    "\n",
    "acc_score = accuracy_score(train['ratingCategory'], y_pred)\n",
    "\n",
    "print(f'Accuracy Score: {(acc_score)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = grid_search.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory': pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461               1\n",
       "1  2604               1\n",
       "2  3341               1\n",
       "3  3764               1\n",
       "4  2306               1"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Try to improve model by using LSI, RF, and GridSearchC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id                                        description  ratingCategory\n",
      "0  1321  \\nSometimes, when whisky is batched, a few lef...               1\n",
      "1  3861  \\nAn uncommon exclusive bottling of a 6 year o...               0\n",
      "2   655  \\nThis release is a port version of Amrut’s In...               1\n",
      "3   555  \\nThis 41 year old single cask was aged in a s...               1\n",
      "4  1965  \\nQuite herbal on the nose, with aromas of dri...               1\n",
      "Pipeline(memory=None,\n",
      "         steps=[('lsi',\n",
      "                 Pipeline(memory=None,\n",
      "                          steps=[('vect',\n",
      "                                  TfidfVectorizer(analyzer='word', binary=False,\n",
      "                                                  decode_error='strict',\n",
      "                                                  dtype=<class 'numpy.float64'>,\n",
      "                                                  encoding='utf-8',\n",
      "                                                  input='content',\n",
      "                                                  lowercase=True, max_df=0.8,\n",
      "                                                  max_features=None,\n",
      "                                                  min_df=0.03,\n",
      "                                                  ngram_range=(1, 2), norm='l2',\n",
      "                                                  preprocessor=None,\n",
      "                                                  smooth_idf=True,\n",
      "                                                  stop_words='english',\n",
      "                                                  strip_accen...\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=20, max_features='auto',\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=2, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=25, n_jobs=-1,\n",
      "                                        oob_score=False, random_state=3,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" READ THE DATA \"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# You may need to change the path\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "print(train.head())\n",
    "\n",
    "\"\"\" MAKE THE PIPELINE \"\"\"\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2), min_df=.03, max_df=.8)\n",
    "svd = TruncatedSVD(n_components=100, \n",
    "                   algorithm='randomized',\n",
    "                   n_iter=10)\n",
    "\n",
    "lsi = Pipeline([('vect', vect), ('svd', svd)])\n",
    "clf = RandomForestClassifier(max_depth=20, n_estimators=25, min_samples_leaf=2, n_jobs=-1, random_state=3)\n",
    "\n",
    "pipe = Pipeline([('lsi', lsi), ('clf', clf)])\n",
    "\n",
    "print(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   44.7s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed: 15.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed: 21.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('lsi',\n",
       "                                        Pipeline(memory=None,\n",
       "                                                 steps=[('vect',\n",
       "                                                         TfidfVectorizer(analyzer='word',\n",
       "                                                                         binary=False,\n",
       "                                                                         decode_error='strict',\n",
       "                                                                         dtype=<class 'numpy.float64'>,\n",
       "                                                                         encoding='utf-8',\n",
       "                                                                         input='content',\n",
       "                                                                         lowercase=True,\n",
       "                                                                         max_df=0.8,\n",
       "                                                                         max_features=None,\n",
       "                                                                         min_df=0.03,\n",
       "                                                                         ngram_range=(1,\n",
       "                                                                                      2),\n",
       "                                                                         norm='l2',\n",
       "                                                                         preprocessor=None,\n",
       "                                                                         smoo...\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'clf__max_depth': (20, 25),\n",
       "                         'clf__n_estimators': (20, 25, 30),\n",
       "                         'lsi__svd__n_components': [100, 150],\n",
       "                         'lsi__vect__max_df': (0.75, 0.8, 0.85),\n",
       "                         'lsi__vect__min_df': (0.02, 0.03),\n",
       "                         'lsi__vect__ngram_range': ((1, 1), (1, 2), (1, 3))},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\" RUN GRID SEARCH CV \"\"\"\n",
    "\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'lsi__svd__n_components': [100,150],\n",
    "    'lsi__vect__max_df': (0.75, .8, .85),\n",
    "    'lsi__vect__min_df': (.02, .03),\n",
    "    'lsi__vect__ngram_range': ((1,1), (1,2), (1,3)),\n",
    "    'clf__max_depth':(20, 25),\n",
    "    'clf__n_estimators': (20, 25, 30)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe,parameters, cv=5, n_jobs=-1, verbose=1) #random_state=3)\n",
    "grid_search.fit(train['description'], train['ratingCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__max_depth': 20,\n",
       " 'clf__n_estimators': 30,\n",
       " 'lsi__svd__n_components': 100,\n",
       " 'lsi__vect__max_df': 0.75,\n",
       " 'lsi__vect__min_df': 0.03,\n",
       " 'lsi__vect__ngram_range': (1, 3)}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7240054705479226"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to improve model by using LSI, XGBoost, and RandomizedSearchCV¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\kingf\\anaconda3\\envs\\u4-s1-nlp\\lib\\site-packages (1.1.0)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scipy in c:\\users\\kingf\\anaconda3\\envs\\u4-s1-nlp\\lib\\site-packages (from xgboost) (1.4.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\kingf\\anaconda3\\envs\\u4-s1-nlp\\lib\\site-packages (from xgboost) (1.18.4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id                                        description  ratingCategory\n",
      "0  1321  \\nSometimes, when whisky is batched, a few lef...               1\n",
      "1  3861  \\nAn uncommon exclusive bottling of a 6 year o...               0\n",
      "2   655  \\nThis release is a port version of Amrut’s In...               1\n",
      "3   555  \\nThis 41 year old single cask was aged in a s...               1\n",
      "4  1965  \\nQuite herbal on the nose, with aromas of dri...               1\n",
      "Pipeline(memory=None,\n",
      "         steps=[('lsi',\n",
      "                 Pipeline(memory=None,\n",
      "                          steps=[('vect',\n",
      "                                  TfidfVectorizer(analyzer='word', binary=False,\n",
      "                                                  decode_error='strict',\n",
      "                                                  dtype=<class 'numpy.float64'>,\n",
      "                                                  encoding='utf-8',\n",
      "                                                  input='content',\n",
      "                                                  lowercase=True, max_df=0.8,\n",
      "                                                  max_features=None,\n",
      "                                                  min_df=0.03,\n",
      "                                                  ngram_range=(1, 2), norm='l2',\n",
      "                                                  preprocessor=None,\n",
      "                                                  smooth_idf=True,\n",
      "                                                  stop_words='english',\n",
      "                                                  strip_accen...\n",
      "                               interaction_constraints=None, learning_rate=None,\n",
      "                               max_delta_step=None, max_depth=None,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=100,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               objective='binary:logistic', random_state=None,\n",
      "                               reg_alpha=None, reg_lambda=None,\n",
      "                               scale_pos_weight=None, subsample=None,\n",
      "                               tree_method=None, validate_parameters=None,\n",
      "                               verbosity=None))],\n",
      "         verbose=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\" READ THE DATA \"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# You may need to change the path\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "print(train.head())\n",
    "\n",
    "\"\"\" MAKE THE PIPELINE (XGBOOST) \"\"\"\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2), min_df=.03, max_df=.8)\n",
    "svd = TruncatedSVD(n_components=100, \n",
    "                   algorithm='randomized',\n",
    "                   n_iter=10)\n",
    "\n",
    "lsi = Pipeline([('vect', vect), ('svd', svd)])\n",
    "clf = XGBClassifier() # max_depth=20, n_estimators=100, min_samples_leaf=2, random_state=3)\n",
    "\n",
    "pipe = Pipeline([('lsi', lsi), ('clf', clf)])\n",
    "\n",
    "print(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 10.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('lsi',\n",
       "                                              Pipeline(memory=None,\n",
       "                                                       steps=[('vect',\n",
       "                                                               TfidfVectorizer(analyzer='word',\n",
       "                                                                               binary=False,\n",
       "                                                                               decode_error='strict',\n",
       "                                                                               dtype=<class 'numpy.float64'>,\n",
       "                                                                               encoding='utf-8',\n",
       "                                                                               input='content',\n",
       "                                                                               lowercase=True,\n",
       "                                                                               max_df=0.8,\n",
       "                                                                               max_features=None,\n",
       "                                                                               min_df=0.03,\n",
       "                                                                               ngram_range=(1,\n",
       "                                                                                            2),\n",
       "                                                                               norm='l2',\n",
       "                                                                               preprocessor=Non...\n",
       "                                                            validate_parameters=None,\n",
       "                                                            verbosity=None))],\n",
       "                                      verbose=False),\n",
       "                   iid='deprecated', n_iter=10, n_jobs=-1,\n",
       "                   param_distributions={'lsi__svd__n_components': [100, 150],\n",
       "                                        'lsi__vect__max_df': (0.75, 0.8, 0.85),\n",
       "                                        'lsi__vect__min_df': (0.02, 0.03),\n",
       "                                        'lsi__vect__ngram_range': ((1, 1),\n",
       "                                                                   (1, 2),\n",
       "                                                                   (1, 3))},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Run randomized search cv\"\"\"\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'lsi__svd__n_components': [100,150],\n",
    "    'lsi__vect__max_df': (0.75, .8, .85),\n",
    "    'lsi__vect__min_df': (.02, .03),\n",
    "    'lsi__vect__ngram_range': ((1,1), (1,2), (1,3))\n",
    "    #'clf__max_depth':(20, 25),\n",
    "    #'clf__n_estimators': (20, 25, 30)\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(pipe,parameters, cv=5, n_jobs=-1, verbose=1) #random_state=3)\n",
    "random_search.fit(train['description'], train['ratingCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lsi__vect__ngram_range': (1, 2),\n",
       " 'lsi__vect__min_df': 0.02,\n",
       " 'lsi__vect__max_df': 0.8,\n",
       " 'lsi__svd__n_components': 100}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7266997453262427"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = random_search.predict(test['description'])\n",
    "\n",
    "# Create the submission dataframe\n",
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory': pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461               1\n",
       "1  2604               1\n",
       "2  3341               0\n",
       "3  3764               1\n",
       "4  2306               1"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to improve model by using upsampling, LSI, XGBoost, and RandomizedSearchCV¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# path to read data\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "minority = train[train['ratingCategory'] == 0]\n",
    "majority = train[train['ratingCategory'] == 1]\n",
    "\n",
    "df_minority_upsampled = resample(minority,\n",
    "                                 replace=True,\n",
    "                                 n_samples=majority.shape[0]\n",
    "                                )\n",
    "\n",
    "df_upsampled = pd.concat([majority, df_minority_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "         steps=[('lsi',\n",
      "                 Pipeline(memory=None,\n",
      "                          steps=[('vect',\n",
      "                                  TfidfVectorizer(analyzer='word', binary=False,\n",
      "                                                  decode_error='strict',\n",
      "                                                  dtype=<class 'numpy.float64'>,\n",
      "                                                  encoding='utf-8',\n",
      "                                                  input='content',\n",
      "                                                  lowercase=True, max_df=0.8,\n",
      "                                                  max_features=None,\n",
      "                                                  min_df=0.03,\n",
      "                                                  ngram_range=(1, 2), norm='l2',\n",
      "                                                  preprocessor=None,\n",
      "                                                  smooth_idf=True,\n",
      "                                                  stop_words='english',\n",
      "                                                  strip_accen...\n",
      "                               interaction_constraints=None, learning_rate=None,\n",
      "                               max_delta_step=None, max_depth=None,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=100,\n",
      "                               n_jobs=None, num_parallel_tree=None,\n",
      "                               objective='binary:logistic', random_state=None,\n",
      "                               reg_alpha=None, reg_lambda=None,\n",
      "                               scale_pos_weight=None, subsample=None,\n",
      "                               tree_method=None, validate_parameters=None,\n",
      "                               verbosity=None))],\n",
      "         verbose=False)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\" MAKE THE PIPELINE (XGBOOST) \"\"\"\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2), min_df=.03, max_df=.8)\n",
    "svd = TruncatedSVD(n_components=100, \n",
    "                   algorithm='randomized',\n",
    "                   n_iter=10)\n",
    "\n",
    "lsi = Pipeline([('vect', vect), ('svd', svd)])\n",
    "clf = XGBClassifier() # max_depth=20, n_estimators=100, min_samples_leaf=2, random_state=3)\n",
    "\n",
    "pipe = Pipeline([('lsi', lsi), ('clf', clf)])\n",
    "\n",
    "print(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  6.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('lsi',\n",
       "                                              Pipeline(memory=None,\n",
       "                                                       steps=[('vect',\n",
       "                                                               TfidfVectorizer(analyzer='word',\n",
       "                                                                               binary=False,\n",
       "                                                                               decode_error='strict',\n",
       "                                                                               dtype=<class 'numpy.float64'>,\n",
       "                                                                               encoding='utf-8',\n",
       "                                                                               input='content',\n",
       "                                                                               lowercase=True,\n",
       "                                                                               max_df=0.8,\n",
       "                                                                               max_features=None,\n",
       "                                                                               min_df=0.03,\n",
       "                                                                               ngram_range=(1,\n",
       "                                                                                            2),\n",
       "                                                                               norm='l2',\n",
       "                                                                               preprocessor=Non...\n",
       "                                                            validate_parameters=None,\n",
       "                                                            verbosity=None))],\n",
       "                                      verbose=False),\n",
       "                   iid='deprecated', n_iter=10, n_jobs=-1,\n",
       "                   param_distributions={'lsi__svd__n_components': [100, 150],\n",
       "                                        'lsi__vect__max_df': (0.75, 0.8, 0.85),\n",
       "                                        'lsi__vect__min_df': (0.02, 0.03),\n",
       "                                        'lsi__vect__ngram_range': ((1, 1),\n",
       "                                                                   (1, 2),\n",
       "                                                                   (1, 3))},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'lsi__svd__n_components': [100,150],\n",
    "    'lsi__vect__max_df': (0.75, .8, .85),\n",
    "    'lsi__vect__min_df': (.02, .03),\n",
    "    'lsi__vect__ngram_range': ((1,1), (1,2), (1,3))\n",
    "    #'clf__max_depth':(20, 25),\n",
    "    #'clf__n_estimators': (20, 25, 30)\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(pipe, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "random_search.fit(df_upsampled['description'], df_upsampled['ratingCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 96.62344017616834%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = random_search.predict(train['description'])\n",
    "\n",
    "acc_score = accuracy_score(train['ratingCategory'], y_pred)\n",
    "\n",
    "print(f'Accuracy Score: {(acc_score)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = random_search.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory': pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
